[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rayures",
    "section": "",
    "text": "An introduction to vector calculus\n\n\n\nMaths\n\n\nMachine learning\n\n\n\n\n\n\n\n\n\n\n\nWhat are heaps and how to implement them in C++\n\n\n\nComputer Science\n\n\nData Structures\n\n\n\n\n\n\n\n\n\n\n\nAn introduction to maximum likelihood estimation and applications to machine learning\n\n\n\nStatistics\n\n\nMachine learning\n\n\n\n\n\n\n\n\n\n\n\nAn introduction to decision trees\n\n\n\nMachine learning\n\n\n\n\n\n\n\n\n\n\n\nIntroducing linear programming and the simplex algorithm\n\n\n\nOptimisation\n\n\nMaths\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/decision_trees.html#a-brief-introduction-to-information-theory",
    "href": "posts/decision_trees.html#a-brief-introduction-to-information-theory",
    "title": "An introduction to decision trees",
    "section": "2.1 A brief introduction to information theory",
    "text": "2.1 A brief introduction to information theory\n\n2.1.1 Information\nWhen training a decision tree on a dataset D = \\{d_1, \\mathellipsis, d_N\\}, we want to choose a feature f : D \\to \\mathcal C_f (where \\mathcal C_f is a finite set of classes) that holds as much information as possible on the class of the data points.\nAn information function is a continuous function I : (0, 1] \\to [0, +\\infty) that satisfies the following conditions:\n\nfor all x, y, I(xy) = I(x) + I(y): if two events are independent, the information that their intersection provides is the sum of the information that each provides;\nI is strictly decreasing: if an event is less likely to happen than an another, knowing whether it happened brings more information.\n\nWe can prove that information functions are exactly the functions \\log_b, where b \\in (0, 1). Equivelently, they are the functions -\\log_b where b &gt; 1. Here is an outline of a proof, given some information function I:\n\nI is a bijection from (0, 1] onto [0, +\\infty): injectivity comes from the fact that is is strictly monotonic and unboundedness comes from the fact that I(1/2^n) = nI(1/2).\nI has an inverse E : [0, +\\infty) \\to (0, 1] that satisfies E(x + y) = E(x)E(y) for all x, y.\nE is continous and agrees with the function r \\mapsto E(1)^r on [0, \\infty) \\cap \\mathbb{Q}, therefore it is the exponential function with base E(1) \\in (0, 1).\nI is therefore the inverse of \\exp_{E(1)}, so I = \\log_{E(1)}.\n\nWe then extend I to [0, 1] by defining I(0) = \\lim_{0} I = +\\infty (which preserves the two axioms).\n\n\n2.1.2 Entropy\nIf a probability measure \\mathbb P on X (where X is either a suitable subset of \\R^n equipped with the borelians or a discrete set with the discrete \\sigma-algebra) has a density f with respect to the Lebesgue or counting measure, we define the entropy of \\mathbb P, denoted H(\\mathbb P) as the expected value of I \\circ f with respect to \\mathbb P: H(\\mathbb P) = \\int_{X} I(f(x)) \\text d\\mathbb P(x) = \\int_{X} I(f(x)) f(x) \\text dx.\n(H is a capital \\eta, and should be pronounced eta and not eitsch…)\nFor simplicity, we pretend that there is a unique information function as the choice of the base does not matter for our purposes.\nThe entropy of a probability measure helps us quantify the amount of information carried by the knowledge of the outcome of a random experiment. For exemple, we can show using Jensen’s inequality that the uniform distribution maximises the entropy over all absolutely-continuous distributions over a certain space (X, \\mu) (where \\mu is the Lebesgue measure or X is finite and \\mu is the counting measure). On the contrary, the entropy of a distribution over a finite set that takes value 1 for one outcome and 0 for every other is 0.\n\n\n2.1.3 Kullback-Leibner divergence\nThe goal of the Kullback-Leibner divergence () is to measure the amount of information carried by a variable about another. For example, consider two binary random variable X and Y that both take values 0 and 1. If \\mathbb P(X = 0 | Y = 0) = \\mathbb P(X = 0 | Y = 1) then Y does not carry any information about X. On the contrary, if \\mathbb P(X = 0 | Y = 0) = 1 and $P(X = 0 | Y = 1) = 0.\nThe KL-div of a variable X given another"
  },
  {
    "objectID": "posts/decision_trees.html#training-for-classification",
    "href": "posts/decision_trees.html#training-for-classification",
    "title": "An introduction to decision trees",
    "section": "2.2 Training for classification",
    "text": "2.2 Training for classification\nWe measure the information held by a feature on the classes of the data points using the entropy of the empirical distribution of classes among"
  },
  {
    "objectID": "posts/decision_trees.html#training-for-regression",
    "href": "posts/decision_trees.html#training-for-regression",
    "title": "An introduction to decision trees",
    "section": "2.3 Training for regression",
    "text": "2.3 Training for regression"
  },
  {
    "objectID": "posts/heaps.html",
    "href": "posts/heaps.html",
    "title": "What are heaps and how to implement them in C++",
    "section": "",
    "text": "This article introduces heaps and shows how to implement them and the basic operations they support in C++."
  },
  {
    "objectID": "posts/heaps.html#accessing",
    "href": "posts/heaps.html#accessing",
    "title": "What are heaps and how to implement them in C++",
    "section": "3.1 Accessing",
    "text": "3.1 Accessing\nIt follows from the heap property that the smallest element of the set of nodes is always the root. This allows us to perform min-peek in constant time, simply by accessing an element of the array by its index.\nstd::optional&lt;T&gt; peek() {\n    if (n == 0) {\n        return {};\n    }\n\n    return array[1];\n}"
  },
  {
    "objectID": "posts/heaps.html#removing",
    "href": "posts/heaps.html#removing",
    "title": "What are heaps and how to implement them in C++",
    "section": "3.2 Removing",
    "text": "3.2 Removing\nHere is a rough description of the algorithm we use to delete the minimum:\n\nreplace the root of the tree with the last element in the tree;\nwhile the last element has at least one child and is greater than one of its children, swap it with its smallest child.\n\nThe image below shows the configuration of a heap throughout the execution of this algorithm.\n\n\n\nIllustration of the pop procedure.\n\n\nThis algorithm runs in linear time with respect to the height of the heap, i.e. in logarithmic time with respect to the number of elements in the heap.\nTo implement it in C++, we start by defining the function rearrangeDown that takes the index of a node and swaps it with its smallest child if appropriate (i.e. if it is not already smaller than its children). It returns the new position of the input node.\nsize_t rearrangeDown(size_t i) {\n    size_t m = i;\n    std::optional&lt;T&gt; l = getLeftChild(i);\n    std::optional&lt;T&gt; r = getRightChild(i);\n    if (l.has_value() && l.value() &lt; array[i]) {\n        m = 2 * i;\n    }\n    if (r.has_value() && r.value() &lt; array[m]) {\n        m = 2 * i + 1;\n    }\n\n    if (m != i) {\n        std::swap(array[m], array[i]);\n        return m;\n    }\n\n    return i;\n}\nm denotes the smallest value between the node at position i, its left child (if it has one) and its right child (if it has one). If i has two children X and Y and the trees rooted at X and at Y both satisfy the heap property, then it can be proved that the tree rooted at i after executing i = rearrangeDown(i) until rearrangeDown(i) == i satisfies the heap property as well.\nWe now implement pop as follows:\nstd::optional&lt;T&gt; pop() {\n    if (n == 0) {\n        return {};\n    }\n\n    T m = array[1];\n\n    array[1] = array[n];\n    size_t i {1};\n    while (true) {\n        size_t newIdx = rearrangeDown(i);\n        if (newIdx == i) break;\n        i = newIdx;\n    }\n\n    --n;\n\n    return m;\n}"
  },
  {
    "objectID": "posts/heaps.html#algorithm",
    "href": "posts/heaps.html#algorithm",
    "title": "What are heaps and how to implement them in C++",
    "section": "5.1 Algorithm",
    "text": "5.1 Algorithm\nLet’s start with an example. Consider the following nearly-complete binary tree.\n\n\n\nA nearly-complete tree to heapify.\n\n\nThe leaves are clearly roots of heaps. If the list we want to heapify has length n then a node k is a leaf if and only if 2k &gt; n, i.e. if and only if k \\ge n/2 + 1 (where \\cdot / \\cdot again denotes euclidean division). We want to make every other node the root of a heap. Let’s start with 3. 3 is less than 6 so (3, 6) satisfies the heap property. Moving to 4. 4 is greater than one of its children (both!), so we swap it with its smallest child, 1. 4 is now a leaf, so it is indeed the root of a heap. Since the tree rooted at 2 and the tree rooted at 1 were both heaps, the tree rooted at 1 in the updated tree is a heap as well. The last node we need to consider is 5. Since 5 &gt; 3 &gt; 1, we swap 5 with 1. 5 is still greater than its children (2 and 4); so we swap 5 with 2. 5 is now a leaf, and the whole tree has become a heap.\nWe implement it as follows:\ntemplate&lt;typename T&gt;\nHeap&lt;T&gt; heapify(std::vector&lt;T&gt; data) {\n    Heap&lt;T&gt; heap;\n    heap.n = data.size();\n    heap.array = {0};\n    for (T x: data) {\n        heap.array.push_back(x);\n    }\n\n    for (size_t i = heap.n / 2; i &gt; 0; --i) {\n        size_t k;\n        size_t j {i};\n        while ((k = heap.rearrangeDown(j)) != j) {\n            j = k;\n        }\n    }\n\n    return heap;\n}\nLines 11 to 15 do exactly the same as lines 9 to 14 in the insert procedure, i.e. it rearrange down the node which is originally at position i until rearrangeDown does not change its position."
  },
  {
    "objectID": "posts/heaps.html#analysis",
    "href": "posts/heaps.html#analysis",
    "title": "What are heaps and how to implement them in C++",
    "section": "5.2 Analysis",
    "text": "5.2 Analysis\nThe sub-procedure in lines 11 to 16 runs in O(\\text{height}(i)) time, for every i between 1 and n/2. Let H be the height of the heap, i.e. H = \\lfloor \\log_2(n) \\rfloor. For every height h between 1 and H (we’re not considering nodes with height 0), there are 2^{H-h} nodes with height h and running the procedure on each of them incurs a cost bounded by h. Therefore, each height h incurs a cost bounded by h2^{H-h} and the overall complexity is given by:\n\\sum_{k = 1}^H h 2^{H-h} = n \\sum_{k = 0}^H h\\frac1{2^h}.\nSince \\sum h\\frac{1}{2^h} converges (which can be shown using an argument involving differentiation of power series), the complexity is linear in the size n of the tree."
  },
  {
    "objectID": "posts/vector_calculus.html",
    "href": "posts/vector_calculus.html",
    "title": "An introduction to vector calculus",
    "section": "",
    "text": "This article introduces the theory of vector calculus. We’ll define what it means for a function from a real vector space onto another to be differentiable, state several theorems that allow to calculate the differential of a differentiable function and see how differentials connect to partial derivatives in the case of finitely-generated vector spaces."
  },
  {
    "objectID": "posts/vector_calculus.html#definition",
    "href": "posts/vector_calculus.html#definition",
    "title": "An introduction to vector calculus",
    "section": "2.1 Definition",
    "text": "2.1 Definition\nLet U and V be real vector spaces, with U being finitely generated with dimension n \\ge 1. Given a fixed canonical basis (e_1, \\mathellipsis, e_n) of U, we say that a function f : U \\to V admits an i-th partial derivative at point x if the function\n\\begin{align*}\n\\lambda \\mapsto \\frac{f(x + \\lambda e_i) - f(x)}{\\lambda}\n\\end{align*}\nhad a limit at 0.\nThe i-th partial derivative at x_0 is then the limit of the above function. \\partial_i f denotes the function that maps x \\in U to the i- th partial derivative of f at x."
  },
  {
    "objectID": "posts/vector_calculus.html#partial-derivatives-and-differentials",
    "href": "posts/vector_calculus.html#partial-derivatives-and-differentials",
    "title": "An introduction to vector calculus",
    "section": "2.2 Partial derivatives and differentials",
    "text": "2.2 Partial derivatives and differentials\nIt can be shown that if a function is differentiable at point x_0 then it admits an i-th partial derivative at x_0, for every i. The converse is not true, however it is sufficient to admit continuous partial derivatives along every component at some point x_0 to be differentiable at x_0. Moreover, the i-th partial derivative of f at x_0 is given by D_{x_0}f(e_i). This means that if V is finitely generated as well then the matrix of D_{x_0}f is (\\partial_j f_i(x_0))_{1 \\le i \\le \\dim(V), 1 \\le j \\le n}. This matrix is known as the Jacobian matrix (of f, at point x_0), that we’ll denote [D_{x_0}f] (or [D_{x_0}f]_{(e_i)} is the choice of the canonical basis is not trivial), or J_{x_0}(f).\nThis result is useful because it allows to effectively store the differential of a function as a matrix.\nIt then follows from the calculation rules we saw earlier that the Jacobian matrix of a linear combination of two functions is the linear combination of their Jacobians, and that the Jacobian of the composition g \\circ f at point x_0 is: [D_{x_0}(g\\circ f)] = [D_{f(x_0)}g] [D_{x_0}f], where juxtaposition denotes matrix multiplication."
  },
  {
    "objectID": "posts/max_likelihood.html",
    "href": "posts/max_likelihood.html",
    "title": "An introduction to maximum likelihood estimation and applications to machine learning",
    "section": "",
    "text": "The maximum likelihood paradigm describes a rule to find a distribution that best fits a set of examples among a parametrised set of distributions. This article defines maximum likelihood estimators and gives two examples of learning models motivated by this paradigm."
  },
  {
    "objectID": "posts/max_likelihood.html#motivation",
    "href": "posts/max_likelihood.html#motivation",
    "title": "An introduction to maximum likelihood estimation and applications to machine learning",
    "section": "1.1 Motivation",
    "text": "1.1 Motivation\nSuppose you have a parametrised set of probability distributions, characterised by density functions with respect to the counting or Lebesgue measure: \\{f_\\vartheta : \\R \\to \\R_+\\}_{\\vartheta \\in \\Theta}.\nSince these measures are closed under translation, we can view the value of their density f_\\vartheta(x) at some point x \\in \\R as an immediate probability (note that this name can be misleading as it is not a probability in the case of Lebesgue-continuous distributions). If we work with the counting measure, this is clear since the value of the density at some point is the actual probability of the point. When working with the Lebesgue measure, this get slightly more subtle and requires a bit of imagination. If the density function is continuous, we can formally justify this intuition by noticing that f_\\vartheta(x) is the limit of the average probability around x: \\lim_{\\delta \\to 0} \\frac{1}{\\delta} \\int_{\\left[x - \\frac\\delta2, x + \\frac\\delta2\\right]} f_\\vartheta\\ \\text d\\mu."
  },
  {
    "objectID": "posts/max_likelihood.html#general-definition",
    "href": "posts/max_likelihood.html#general-definition",
    "title": "An introduction to maximum likelihood estimation and applications to machine learning",
    "section": "1.2 General definition",
    "text": "1.2 General definition\nFrom this intuition, we can define the likelihood of a sequence of independent and identically-distributed observations \\mathbf{x} = \\{x_1, \\mathellipsis, x_n\\} as L(\\vartheta) = f_\\vartheta^n(\\mathbf{x}), where f_\\vartheta^n is the joint probability distribution over sequences of n independent f_\\vartheta-distributed examples. We then have: L(\\vartheta) = \\prod_{j = 1}^n f_\\vartheta(x_j).\nFrom a computational perspective, we often prefer to deal with the \\log-likelihood of a sequence of examples rather than their likelihood:\n\\log L(\\vartheta) = \\sum_{j = 1}^n \\log\\left(f_\\vartheta(x_j)\\right).\nWe then define the maximum-likelihood estimator of \\vartheta as:\n\\hat\\vartheta_{\\text{ml}} = \\argmax_{\\vartheta \\in \\Theta} L(\\vartheta),\nwhere the existence and uniqueness of the argmax is assumed.\nNote that since \\log is strictly increasing, \\argmax_\\vartheta L(\\vartheta) = \\argmax_\\vartheta (\\log(L(\\vartheta)))."
  },
  {
    "objectID": "posts/max_likelihood.html#approximating-distribution-of-inputoutput-pairs-with-conditional-maximumum-likelihood",
    "href": "posts/max_likelihood.html#approximating-distribution-of-inputoutput-pairs-with-conditional-maximumum-likelihood",
    "title": "An introduction to maximum likelihood estimation and applications to machine learning",
    "section": "1.3 Approximating distribution of input/output pairs with conditional maximumum likelihood",
    "text": "1.3 Approximating distribution of input/output pairs with conditional maximumum likelihood\nSimilarly, we can use the maximum likelihood paradigm to find a distribution that best describes a set of observations of the form \\{(x_1, y_1), \\mathellipsis, (x_n, y_n)\\}, where y_j is viewed as an output associated with input x_j. For every x_j, we consider the density functions f_\\vartheta(\\cdot | x_j) across all \\vartheta \\in \\Theta. We then define the likelihood of the set of observations for parameter \\vartheta as the density function of the random vector sequence (Y_1, \\mathellipsis, Y_n), where Y_j \\sim f_\\theta(\\cdot | x_j), evaluated at (y_1, \\mathellipsis, y_n) i.e. L(\\vartheta) = \\prod_{j = 1}^n f_\\vartheta(y_j | x_j)."
  },
  {
    "objectID": "posts/linear_programming_1.html",
    "href": "posts/linear_programming_1.html",
    "title": "Introducing linear programming and the simplex algorithm",
    "section": "",
    "text": "Linear programming is the study of linear problems and ways of solving them. A linear problem is an optimisation problem where we seek to maximise a linear function on a domain defined as the intersection of the sets of solutions of finitely-many linear inequalities. In this article, we’ll define linear problems, describe an algorithm used to solve them and implement a C++ library with utilities to define and solve linear problems.\n\n1 Definition\nLet n, p \\in \\N^* be two positive integers. n is the input dimension and p is the constraint dimension. Let c \\in \\R^n and z = \\bra{c} the objective function that maps x \\in \\R^n to the real number \\langle c, x\\rangle (where \\langle \\cdot, \\cdot \\rangle denotes the standard scalar product on \\R^n). Let A \\in \\R^{p, n} be a p \\times n matrix with real entries and b \\in \\R^{p, 1} be a column vector. c, A and b characterise the standard form or the canonical form of a linear problem. The canonical form describes the following problem: \\begin{align*}\n\\max && z(x)\\\\\n\\text{subject to} && Ax \\le b\\\\\n&& x \\ge 0,\n\\end{align*} where inequalities should be read componentwise, i.e. u \\le v if and only if for every index i, u_i \\le v_i.\nThe standard form describes the same problem but where Ax \\le b was replaced by Ax = b: \\begin{align*}\n\\max && z(x)\\\\\n\\text{subject to} && Ax = b\\\\\n&& x \\ge 0,\n\\end{align*}\nA linear problem is one that can be formulated into a standard form or a canonical form. These two formulations are equivalent, in the sense that canonical forms can be reformulated into standard forms, and conversely .\n\na constraint of the form \\langle c_i, x \\rangle = b_i can be expressed as the intersection of \\langle c_i, x \\rangle \\le b_i and \\langle -c_i, x \\rangle \\le -b_i\na constraint of the form \\langle c_i, x \\rangle \\le b_i can be expressed as a constraint of the form \\langle c_i, x \\rangle + 1 \\times s_i = b_i by augmenting the input vector x by adding a new non-negative component s_i.\n\nComponents s_i that are used to turn weak inequalities into equalities are called slack variables."
  }
]